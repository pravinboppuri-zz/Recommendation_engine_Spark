{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import FloatType\n",
    "import MySQLdb\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName(\"app_collaborative\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setCheckpointDir('checkpoint/')\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#USER_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_RANK = 15\n",
    "BEST_ITERATION = 20\n",
    "BEST_REGULATION = 0.100000\n",
    "\n",
    "#Rank 15\n",
    "#Regul 0.100000\n",
    "#Iter 20\n",
    "#Dist 1.084007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings ='/home/bella/Downloads/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs ='/home/bella/Downloads/jobs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfratings = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+\n",
      "|userid|jobid|rating|\n",
      "+------+-----+------+\n",
      "|    10|    1|     1|\n",
      "|    18|    1|     2|\n",
      "|    13|    1|     1|\n",
      "|     7|    2|     2|\n",
      "|     4|    2|     2|\n",
      "|    13|    2|     3|\n",
      "|    19|    2|     2|\n",
      "|    12|    2|     1|\n",
      "|    11|    2|     1|\n",
      "|     1|    2|     2|\n",
      "|    20|    2|     2|\n",
      "|     2|    2|     4|\n",
      "|     3|    2|     1|\n",
      "|     0|    3|     4|\n",
      "|     4|    3|     5|\n",
      "|     8|    3|     4|\n",
      "|     7|    3|     4|\n",
      "|    10|    3|     5|\n",
      "|    16|    3|     5|\n",
      "|    21|    3|     5|\n",
      "+------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjobs = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------+------+--------+--------------------+\n",
      "| id|zipcode|         city|radius|category|               items|\n",
      "+---+-------+-------------+------+--------+--------------------+\n",
      "|  1|     50|    Vancouver|     3| cottage|  Comfy Quiet Chalet|\n",
      "|  2|     65|       London|     2| cottage|       Cozy Calm Hut|\n",
      "|  3|     65|       London|     4|   house| Agreable Calm Place|\n",
      "|  4|   3400|        Paris|    16|  castle|Colossal Quiet Ch...|\n",
      "|  5|     50|        Paris|     1| cottage|    Homy Quiet Shack|\n",
      "|  6|     35|       Dublin|     5|   house|Pleasant Quiet Place|\n",
      "|  7|   3200|      Seattle|    24|  castle|Vast Peaceful For...|\n",
      "|  8|   3400|San Francisco|    12|  castle|Giant Quiet Fortress|\n",
      "|  9|   1500|       London|    20|  castle|Giant Peaceful Pa...|\n",
      "| 10|    650|     Auckland|     9| mansion|Sizable Calm Coun...|\n",
      "| 11|     50|    Melbourne|     1| cottage|   Homy Quiet Shanty|\n",
      "| 12|     90|      Seattle|     2|   house|Beautiful Peacefu...|\n",
      "| 13|   3300|    Melbourne|    12|  castle|Enormous Peaceful...|\n",
      "| 14|   1200|    Melbourne|    21|  castle|Colossal Peaceful...|\n",
      "| 15|   1300|       London|    18|  castle|   Vast Private Fort|\n",
      "| 16|     45|    Melbourne|     3|   house|    Large Calm House|\n",
      "| 17|    850|          NYC|     9| mansion|Large Calm Sately...|\n",
      "| 18|     60|    Melbourne|     2| cottage|    Big Peaceful Hut|\n",
      "| 19|   4500|        Paris|    18|  castle|  Giant Quiet Castle|\n",
      "| 20|    650| Buenos Aires|    12| mansion|    Big Private Hall|\n",
      "+---+-------+-------------+------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfjobs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userid: string (nullable = true)\n",
      " |-- jobid: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- radius: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- items: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfjobs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'4', u'5', u'5', u'4', u'4', u'4', u'5', u'4', u'4']\n"
     ]
    }
   ],
   "source": [
    "# Get all the ratings rows of our user\n",
    "dfUserRatings  = dfratings.filter(dfratings.userid == USER_ID).rdd.map(lambda r: r.rating).collect()\n",
    "print(dfUserRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns only the accommodations that have not been rated by our user\n",
    "rddPotential  = dfjobs.rdd.filter(lambda x: x[0] not in dfUserRatings)\n",
    "pairsPotential = rddPotential.map(lambda x: (USER_ID, x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=u'1', zipcode=u'50', city=u'Vancouver', radius=u'3', category=u'cottage', items=u'Comfy Quiet Chalet'),\n",
       " Row(id=u'2', zipcode=u'65', city=u'London', radius=u'2', category=u'cottage', items=u'Cozy Calm Hut'),\n",
       " Row(id=u'3', zipcode=u'65', city=u'London', radius=u'4', category=u'house', items=u'Agreable Calm Place'),\n",
       " Row(id=u'6', zipcode=u'35', city=u'Dublin', radius=u'5', category=u'house', items=u'Pleasant Quiet Place'),\n",
       " Row(id=u'7', zipcode=u'3200', city=u'Seattle', radius=u'24', category=u'castle', items=u'Vast Peaceful Fortress'),\n",
       " Row(id=u'8', zipcode=u'3400', city=u'San Francisco', radius=u'12', category=u'castle', items=u'Giant Quiet Fortress'),\n",
       " Row(id=u'9', zipcode=u'1500', city=u'London', radius=u'20', category=u'castle', items=u'Giant Peaceful Palace'),\n",
       " Row(id=u'10', zipcode=u'650', city=u'Auckland', radius=u'9', category=u'mansion', items=u'Sizable Calm Country House'),\n",
       " Row(id=u'11', zipcode=u'50', city=u'Melbourne', radius=u'1', category=u'cottage', items=u'Homy Quiet Shanty'),\n",
       " Row(id=u'12', zipcode=u'90', city=u'Seattle', radius=u'2', category=u'house', items=u'Beautiful Peaceful Villa')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddPotential.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, u'1'),\n",
       " (0, u'2'),\n",
       " (0, u'3'),\n",
       " (0, u'6'),\n",
       " (0, u'7'),\n",
       " (0, u'8'),\n",
       " (0, u'9'),\n",
       " (0, u'10'),\n",
       " (0, u'11'),\n",
       " (0, u'12')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairsPotential.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', '6', 4.980718420810856), ('0', '49', 4.930697708110878), ('0', '30', 4.761530993343464), ('0', '12', 4.7031064643388145), ('0', '75', 4.699257084373732), ('0', '76', 4.5257146667411785), ('0', '66', 4.517683683636025), ('0', '61', 4.350737627739173), ('0', '3', 4.3063850570006315), ('0', '59', 4.2360345375641355)]\n"
     ]
    }
   ],
   "source": [
    "rddTraining, rddValidating, rddTesting = dfratings.rdd.randomSplit([6,2,2])\n",
    "\n",
    "model = ALS.train(rddTraining, BEST_RANK, BEST_ITERATION, BEST_REGULATION)\n",
    "\n",
    "# Calculate all predictions\n",
    "predictions = model.predictAll(pairsPotential).map(lambda p: (str(p[0]), str(p[1]), float(p[2])))\n",
    "\n",
    "# Take the top 5 ones\n",
    "topPredictions = predictions.takeOrdered(10, key=lambda x: -x[2])\n",
    "print(topPredictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"userId\", StringType(), True), StructField(\"jobid\", StringType(), True), StructField(\"prediction\", FloatType(), True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfToSave = sqlContext.createDataFrame(topPredictions, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "_delimiter=','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "_output='/home/bella/Downloads/predictions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "_xy=dfToSave.coalesce(1).write.format('com.databricks.spark.csv').option('header','true').option('delimiter', _delimiter).mode(\"overwrite\").save(_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
